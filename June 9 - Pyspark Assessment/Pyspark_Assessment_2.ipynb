{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"HR_Analytics\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj48o-C2mqT0",
        "outputId": "196aa00b-1774-409a-ffb3-7b4dc55e9137"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read files\n",
        "employees_df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
        "attendance_df = spark.read.csv(\"attendance.csv\", header=True, inferSchema=True)\n",
        "bonuses_df = spark.read.json(\"bonuses.json\")\n",
        "\n",
        "# Show schemas and sample data\n",
        "employees_df.printSchema()\n",
        "employees_df.show()\n",
        "\n",
        "attendance_df.printSchema()\n",
        "attendance_df.show()\n",
        "\n",
        "bonuses_df.printSchema()\n",
        "bonuses_df.show()\n",
        "\n",
        "# Count distinct departments\n",
        "employees_df.select(\"Department\").distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7RA1rwGmqWd",
        "outputId": "983dccee-e1f7-4006-a162-1b1acb65a550"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "|    3|2024-04-02|Present|\n",
            "|    4|2024-04-01| Absent|\n",
            "|    4|2024-04-02| Absent|\n",
            "|    5|2024-04-01|Present|\n",
            "|    5|2024-04-02|Present|\n",
            "+-----+----------+-------+\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "source": [
        "# Add TenureYears column\n",
        "from pyspark.sql.functions import datediff, current_date, round, col\n",
        "employees_df = employees_df.withColumn(\n",
        "    \"TenureYears\",\n",
        "    round(datediff(current_date(), col(\"JoinDate\")) / 365, 1)\n",
        ")\n",
        "\n",
        "# Calculate TotalCompensation (Salary + Bonus)\n",
        "from pyspark.sql.functions import coalesce, lit\n",
        "employees_with_bonus = employees_df.join(bonuses_df, \"EmpID\", \"left\")\n",
        "employees_with_bonus = employees_with_bonus.withColumn(\n",
        "    \"TotalCompensation\",\n",
        "    col(\"Salary\") + coalesce(col(\"Bonus\"), lit(0))\n",
        ")\n",
        "\n",
        "# Filter employees with >2 years tenure\n",
        "employees_df.filter(col(\"TenureYears\") > 2).show()\n",
        "\n",
        "# Employees with managers\n",
        "employees_df.filter(col(\"ManagerID\").isNotNull()).show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdfOkGh910dj",
        "outputId": "68828cf9-22bd-4b8e-b4e1-c547bd21c7c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Average salary per department\n",
        "from pyspark.sql.functions import avg # Import the avg function\n",
        "employees_df.groupBy(\"Department\").agg(avg(\"Salary\").alias(\"AvgSalary\")).show()\n",
        "\n",
        "# Employees per manager\n",
        "employees_df.groupBy(\"ManagerID\").count().show()\n",
        "\n",
        "# Absences per employee\n",
        "attendance_df.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").count().show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDG0FKtf2dtP",
        "outputId": "f3d5d1d8-6a5c-4882-8621-e876e4714805"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+\n",
            "| Department|AvgSalary|\n",
            "+-----------+---------+\n",
            "|Engineering|  77500.0|\n",
            "|         HR|  52500.0|\n",
            "|  Marketing|  60000.0|\n",
            "+-----------+---------+\n",
            "\n",
            "+---------+-----+\n",
            "|ManagerID|count|\n",
            "+---------+-----+\n",
            "|     NULL|    1|\n",
            "|        1|    4|\n",
            "+---------+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|EmpID|count|\n",
            "+-----+-----+\n",
            "|    4|    2|\n",
            "|    2|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Attendance percentage\n",
        "from pyspark.sql.functions import count, sum, when # Import count, sum, and when\n",
        "from pyspark.sql.functions import col # col was already imported, but including here for clarity\n",
        "attendance_summary = attendance_df.groupBy(\"EmpID\").agg(\n",
        "    count(\"*\").alias(\"TotalDays\"),\n",
        "    sum(when(col(\"Status\") == \"Present\", 1).otherwise(0)).alias(\"PresentDays\")\n",
        ").withColumn(\"AttendancePercentage\", (col(\"PresentDays\") / col(\"TotalDays\")) * 100)\n",
        "\n",
        "employee_attendance = employees_df.join(attendance_summary, \"EmpID\", \"left\")\n",
        "employee_attendance.show()\n",
        "\n",
        "# Top 3 by TotalCompensation\n",
        "employees_with_bonus.orderBy(col(\"TotalCompensation\").desc()).limit(3).show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKclaTQX2lB4",
        "outputId": "2f03e71c-7ebf-406e-d5ec-2cae4b846233"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+--------------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|TotalDays|PresentDays|AttendancePercentage|\n",
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+--------------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|        2|          2|               100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|        2|          1|                50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|        2|          2|               100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|        2|          0|                 0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|        2|          2|               100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+---------+-----------+--------------------+\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6| 6000|2023|            66000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create database and tables\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS hr\")\n",
        "spark.sql(\"USE hr\")\n",
        "\n",
        "employees_df.write.mode(\"overwrite\").saveAsTable(\"hr.employees\")\n",
        "attendance_df.write.mode(\"overwrite\").saveAsTable(\"hr.attendance\")\n",
        "bonuses_df.write.mode(\"overwrite\").saveAsTable(\"hr.bonuses\")\n",
        "\n",
        "# Run SQL queries\n",
        "spark.sql(\"SELECT Department, Name, Salary FROM employees WHERE Salary > 50000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBMbuXmtmqZM",
        "outputId": "8b647d5f-8f50-4580-e060-bce5edcf042e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+------+\n",
            "| Department|  Name|Salary|\n",
            "+-----------+------+------+\n",
            "|         HR| Anita| 55000|\n",
            "|Engineering|   Raj| 80000|\n",
            "|Engineering|Simran| 75000|\n",
            "|  Marketing| Aamir| 60000|\n",
            "+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UDF for Tech/Non-Tech classification\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def dept_classifier(dept):\n",
        "    return \"Tech\" if dept == \"Engineering\" else \"Non-Tech\"\n",
        "\n",
        "dept_udf = udf(dept_classifier, StringType())\n",
        "employees_df.withColumn(\"DeptType\", dept_udf(col(\"Department\"))).show()\n",
        "\n",
        "# Save as Parquet\n",
        "employee_attendance.write.partitionBy(\"Department\").parquet(\"employee_attendance.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCjC_pZomqb7",
        "outputId": "a55fcd57-2b71-47ed-9cb7-9eb7ec990269"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|DeptType|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|        4.1|Non-Tech|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|        5.2|    Tech|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|        2.9|    Tech|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|        5.6|Non-Tech|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|        2.4|Non-Tech|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "LOX5G2LTmqfd"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}