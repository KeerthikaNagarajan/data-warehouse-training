{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d79e970-b27a-448a-bf83-d974047b7f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "enrollments_path = \"file:/Workspace/Shared/course_enrollments.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(enrollments_path)\n",
    "\n",
    "df = df.withColumn(\"EnrollDate\", to_date(\"EnrollDate\")) \\\n",
    "       .withColumn(\"CompletionDate\", to_date(\"CompletionDate\"))\n",
    "df = df.withColumn(\"DaysToComplete\", \n",
    "                   datediff(\"CompletionDate\", \"EnrollDate\").cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4fd3940-3b3b-4a2c-8e07-1bac3746926e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "user_courses = df.groupBy(\"UserID\").agg(\n",
    "    count(\"*\").alias(\"CoursesEnrolled\"),\n",
    "    avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"IsCompleted\", col(\"ProgressPercent\") == 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69059c00-380e-45a1-baf7-4e8c9ca4f4ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Rating\", coalesce(col(\"Rating\"), lit(0)))\n",
    "df = df.withColumn(\"EngagementScore\", col(\"ProgressPercent\") * col(\"Rating\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c890a209-695b-4eb7-8842-f7a3577e6b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dropouts = df.filter((col(\"ProgressPercent\") < 50) & col(\"CompletionDate\").isNull())\n",
    "dropouts.createOrReplaceTempView(\"Dropouts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8551952e-2956-42b8-a7a7-50c10451b352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "catalog_path = \"file:/Workspace/Shared/course_catalog.csv\"\n",
    "\n",
    "catalog_schema = StructType([\n",
    "    StructField(\"CourseID\", StringType(), True),\n",
    "    StructField(\"Instructor\", StringType(), True),\n",
    "    StructField(\"DurationHours\", IntegerType(), True),\n",
    "    StructField(\"Level\", StringType(), True)\n",
    "])\n",
    "\n",
    "catalog_df = spark.read.option(\"header\", True).schema(catalog_schema).csv(catalog_path)\n",
    "\n",
    "joined_df = df.join(catalog_df, on=\"CourseID\", how=\"left\")\n",
    "progress_by_instructor = joined_df.groupBy(\"Instructor\").agg(avg(\"ProgressPercent\").alias(\"AvgProgress\"))\n",
    "\n",
    "most_enrolled = df.groupBy(\"CourseID\").count().orderBy(col(\"count\").desc()).limit(1)\n",
    "most_enrolled_course = most_enrolled.join(catalog_df, \"CourseID\", \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8aa2a4b-2985-48fb-ae75-10437c9593d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|version|           timestamp|          userId|            userName|operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n",
      "+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "|      3|2025-06-19 04:58:...|7868838587549447|azuser3557_mml.lo...| OPTIMIZE|{predicate -> [],...|NULL|{1222209826929636}|0619-042535-5t46f450|          1|SnapshotIsolation|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      2|2025-06-19 04:58:...|7868838587549447|azuser3557_mml.lo...|   DELETE|{predicate -> [\"(...|NULL|{1222209826929636}|0619-042535-5t46f450|          1|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      1|2025-06-19 04:58:...|7868838587549447|azuser3557_mml.lo...|   UPDATE|{predicate -> [\"(...|NULL|{1222209826929636}|0619-042535-5t46f450|          0|WriteSerializable|        false|{numRemovedFiles ...|        NULL|Databricks-Runtim...|\n",
      "|      0|2025-06-19 04:58:...|7868838587549447|azuser3557_mml.lo...|    WRITE|{mode -> Overwrit...|NULL|{1222209826929636}|0619-042535-5t46f450|       NULL|WriteSerializable|        false|{numFiles -> 1, n...|        NULL|Databricks-Runtim...|\n",
      "+-------+--------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "delta_path = \"file:/Workspace/Shared/enrollments_delta\"\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "delta_table.update(\n",
    "    condition=\"CourseName = 'Python Basics'\",\n",
    "    set={\"Rating\": \"5\"}\n",
    ")\n",
    "delta_table.delete(\"ProgressPercent = 0\")\n",
    "delta_table.history().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37940f81-887d-4c0a-8505-7531fd0c9792",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "course_counts = df.groupBy(\"CourseID\").count()\n",
    "window_spec = Window.orderBy(col(\"count\").desc())\n",
    "course_counts = course_counts.withColumn(\"Rank\", dense_rank().over(window_spec))\n",
    "user_window = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "df = df.withColumn(\"NextCourseID\", lead(\"CourseID\").over(user_window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb46cacc-5751-4f5c-a996-9882845a71e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"enrollments\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW daily_enrollments AS\n",
    "SELECT EnrollDate, COUNT(*) AS TotalEnrollments\n",
    "FROM enrollments\n",
    "GROUP BY EnrollDate\n",
    "ORDER BY EnrollDate\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW category_performance AS\n",
    "SELECT Category, AVG(Rating) AS AvgRating\n",
    "FROM enrollments\n",
    "GROUP BY Category\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW top_3_courses AS\n",
    "SELECT CourseName, COUNT(*) AS Enrollments\n",
    "FROM enrollments\n",
    "GROUP BY CourseName\n",
    "ORDER BY Enrollments DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "937e23db-c328-4eec-be3c-b10257f0fcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+---------------+\n",
      "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|EngagementScore|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+---------------+\n",
      "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|       true|            400|\n",
      "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|      false|              0|\n",
      "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|      false|              0|\n",
      "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|       true|            500|\n",
      "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|       true|            400|\n",
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "df_version_0.show()\n",
    "\n",
    "df.write.mode(\"overwrite\").partitionBy(\"Category\").json(\"file:/Workspace/Shared/output_json\")\n",
    "summary_df = df.groupBy(\"CourseName\").agg(\n",
    "    count(\"*\").alias(\"TotalEnrollments\"),\n",
    "    avg(\"Rating\").alias(\"AvgRating\"),\n",
    "    avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
    ")\n",
    "\n",
    "summary_df.write.mode(\"overwrite\").parquet(\"file:/Workspace/Shared/course_summary\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SET-2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
